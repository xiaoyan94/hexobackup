---
title: Hadoop：分布式资源调度YARN
date: 2020-06-18 14:48:12
tags: [Hadoop, YARN]
---

**YARN**全称：Yet Another Resource Negotiator。

一个Cluster Resource Management

<!--more-->

## YARN产生背景

MapReduce1.x存在的问题：

- 单点故障&节点压力大不易扩展
- 资源利用率低&运维成本高

Hadoop1.x时:  

MapReduce: Master/Slave架构， 1个JobTracker带多个TaskTracker  
JobTracker: 负责资源管理和作业调度  
TaskTracker: 定期向JT汇报本节点的健康状况、资源使用情况、作业执行情况;
接收来自JT的命令:启动任务/杀死任务

**YARN**:

不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度  
XXX on YARN的好处:
与其他计算框架共享集群资源，按资源需要分配，进而提高集群资源的利用率  
XXX: Spark/MapReduce/Storm/Flink

## 基本思想

MapReduce v2版本的**基本思想**是将JobTracker的两个主要功能（**资源管理和作业计划/监视**）拆分为单独的守护程序。 想法是拥有一个全局**ResourceManager**（RM）和每个应用程序的**ApplicationMaster**（AM）。 一个应用程序（Application）要么是传统意义上的Map-Reduce作业中的单个作业，要么是作业的DAG（有向无环图）。

---

## 主要组件

![Yarn架构和主要组件](yarn_architecture.gif)

ResourceManager和每个节点的从属节点NodeManager（NM）构成了数据计算框架。 ResourceManager是在系统中所有应用程序之间仲裁资源的最终权限。

每个应用程序的ApplicationMaster实际上是一个框架特定库，其任务是协商来自ResourceManager的资源，并与NodeManager一起执行和监视任务。

ResourceManager具有两个主要组件：Scheduler和ApplicationsManager。  

Scheduler负责将资源分配给各种正在运行的应用程序，这些应用程序受到常见的能力、队列等约束。  
Scheduler是纯调度器，因为它不监视或跟踪应用程序的状态。此外，它不能保证重新启动*由于应用程序失败或硬件失败而失败的*任务。  
Scheduler基于应用程序的资源要求执行其调度功能；它基于资源容器的抽象概念来执行此功能，资源容器合并了内存、CPU、磁盘、网络等元素。在第一个版本中，仅支持内存。  
Scheduler有一个可插拔的策略插件，负责在各种队列、应用程序等之间划分集群资源。Map-Reduce调度器(如CapacityScheduler和FairScheduler)就是该插件的一些示例。  
CapacityScheduler支持分层队列（*hierarchical queues*），以使群集资源的共享更加可预测。

ApplicationsManager负责接受作业提交，协商用于执行特定于应用程序的ApplicationMaster的第一个容器，并提供在失败时重新启动ApplicationMaster容器的服务。

Container： 封装了CPU、Memory等资源的容器。

NodeManager是每台机器的框架代理，负责容器，监视其资源使用情况（cpu，内存，磁盘，网络），并将其报告给ResourceManager / Scheduler。

每个应用程序的ApplicationMaster负责从Scheduler协商适当的资源容器，跟踪它们的状态并监视进度。

MRV2与以前的稳定版本（hadoop-1.x）保持API兼容性。这意味着，所有Map Reduce作业都应该在MRv2的基础上以不变的方式运行，只需重新编译。

---

## YARN环境搭建

Hadoop版本：hadoop-2.6.0-cdh5.7.0

### 服务器配置

依然是在伪分布式环境：  
Hadoop也可以以伪分布式模式在单节点上运行，其中每个Hadoop守护程序都在单独的Java进程中运行。  
通过设置一些参数并运行ResourceManager守护进程和NodeManager守护进程，可以在伪分布式模式下在YAR上运行MapReduce作业。

打开以下配置文件：Hadoop安装目录/etc/hadoop/mapred-site.xml:

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

Hadoop安装目录/etc/hadoop/yarn-site.xml:

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

### 启动与停止YARN服务

启动ResourceManager守护程序和NodeManager守护程序：

```bash
$ $HADOOP_HOME/sbin/start-yarn.sh
$
```

`jps`命令查看RM和NM进程是否启动成功  
ResourceManager Web管理界面： <http://server-ip:8088/>

运行MapReduce作业：  
使用`hadoop jar`命令提交MapReduce作业到yarn运行。

停止YARN守护进程：

```bash
$ $HADOOP_HOME/sbin/stop-yarn.sh
$
```

---

[真·分布式集群配置](https://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0/hadoop-project-dist/hadoop-common/ClusterSetup.html)
